{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWWwiP9QkJQO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Tuple\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFile\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(predicted_batch: torch.Tensor, label_batch: torch.Tensor) -> float:\n",
        "    pred = predicted_batch.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    acum = pred.eq(label_batch.view_as(pred)).sum().item()\n",
        "    return acum"
      ],
      "metadata": {
        "id": "ujjO7cX2mvD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "_ = torch.manual_seed(seed)\n",
        "_ = torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "U5MpV9YNmMI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we select to work on GPU if it is available in the machine, otherwise will run on CPU\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptwtKKxfmNp9",
        "outputId": "a0731280-0e5a-435f-9493-5764422f4787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define some hyper-parameters\n",
        "hparams = {\n",
        "    # Original: 256\n",
        "    'batch_size': 32,\n",
        "    # Original: 10\n",
        "    'num_epochs': 5,\n",
        "    # Original: 256\n",
        "    'test_batch_size': 32,\n",
        "    'learning_rate': 0.01,\n",
        "    'weight_decay': 1e-5,\n",
        "    'log_interval': 10,\n",
        "}"
      ],
      "metadata": {
        "id": "omUPP_zRmPfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLkdJ0PBWZhb",
        "outputId": "360d74f5-8d7c-431e-a264-c698d22891ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "f_-4XIUZmVDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Print the current working directory\n",
        "current_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wIMVF0tqmbC9",
        "outputId": "675d7e14-cdec-41b4-d888-d60a8b3d132d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the path to the directory\n",
        "initial_path = '/content/drive/MyDrive/06_ia/09_final_project/07_project'\n",
        "dataset_path = '/dataset'\n",
        "\n",
        "# List the contents of the directory\n",
        "contents = os.listdir(initial_path + dataset_path)\n",
        "\n",
        "# Print the contents of the directory\n",
        "for item in contents:\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdfTYmmOmcdH",
        "outputId": "b9a3b5d6-a4e5-4841-fb35-4ab6774f8a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid\n",
            "train\n",
            "test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qVnHJUY9mlS4",
        "outputId": "bc51912d-69d8-4ff6-fbb0-a463f7a175f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/06_ia/09_final_project/07_project'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DTOZMPk7o6XB",
        "outputId": "3ca7f64c-9198-4ade-f7b5-9a0584cd3498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyZ_8dkfo8FO",
        "outputId": "c5dd5306-4c15-49fd-c22c-7209b21ab6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['valid', 'train', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining paths of train, validation and test data\n",
        "train_path = initial_path + dataset_path + \"/train\"\n",
        "test_path = initial_path + dataset_path + \"/test\"\n",
        "valid_path = initial_path + dataset_path + \"/valid\"\n",
        "\n",
        "print(\"Training data: \" + train_path)\n",
        "print(\"Test data: \" + test_path)\n",
        "print(\"Validation data: \" + valid_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5XtFtmNo94K",
        "outputId": "f033ca85-d48c-4778-8fee-d91b9df1eba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: /content/drive/MyDrive/06_ia/09_final_project/07_project/dataset/train\n",
            "Test data: /content/drive/MyDrive/06_ia/09_final_project/07_project/dataset/test\n",
            "Validation data: /content/drive/MyDrive/06_ia/09_final_project/07_project/dataset/valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining image transformations\n",
        "image_transforms = transforms.Compose([\n",
        "        transforms.Resize((350, 350)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                             [0.5, 0.5, 0.5])\n",
        "    ])"
      ],
      "metadata": {
        "id": "v3mjtTPbpADV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading training data using DataLoader\n",
        "train_data = ImageFolder(train_path, transform=image_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=hparams['batch_size'], shuffle=True)"
      ],
      "metadata": {
        "id": "ztoE8_kppd8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading test data using DataLoader\n",
        "test_data = ImageFolder(test_path, transform=image_transforms)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=hparams['batch_size'], shuffle=False)\n",
        "\n",
        "# loading validation data using DataLoader\n",
        "val_data = ImageFolder(valid_path, transform=image_transforms)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=hparams['batch_size'], shuffle=False)"
      ],
      "metadata": {
        "id": "XTfMKA1LpfvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve a sample from the dataset by simply indexing it\n",
        "img, label = train_data[0]\n",
        "print('Img shape: ', img.shape)\n",
        "print('Label: ', label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afe9niChqB49",
        "outputId": "6b84bf12-8ff6-49c3-c0cd-7a98eb9704af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Img shape:  torch.Size([3, 350, 350])\n",
            "Label:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample a BATCH from the dataloader by running over its iterator\n",
        "iter_ = iter(train_loader)\n",
        "bimg, blabel = next(iter_)\n",
        "print('Batch Img shape: ', bimg.shape)\n",
        "print('Batch Label shape: ', blabel.shape)\n",
        "print('Batch Img shape: ', bimg.shape)\n",
        "print('Batch Label shape: ', blabel.shape)\n",
        "print(f'The Batched tensors return a collection of {bimg.shape[0]} images \\\n",
        "({bimg.shape[1]} channel, {bimg.shape[2]} height pixels, {bimg.shape[3]} width \\\n",
        "pixels)')\n",
        "print(f'In the case of the labels, we obtain {blabel.shape[0]} batched integers, one per image')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl-F2OipqDAa",
        "outputId": "46680538-4bf2-4ae0-a625-bc88d2da9e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Img shape:  torch.Size([32, 3, 350, 350])\n",
            "Batch Label shape:  torch.Size([32])\n",
            "Batch Img shape:  torch.Size([32, 3, 350, 350])\n",
            "Batch Label shape:  torch.Size([32])\n",
            "The Batched tensors return a collection of 32 images (3 channel, 350 height pixels, 350 width pixels)\n",
            "In the case of the labels, we obtain 32 batched integers, one per image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class idx + names\n",
        "class_names = train_data.class_to_idx\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-vtRU-trguD",
        "outputId": "72f2f5f0-eae8-4c31-d21a-ab10cb322a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nowildfire': 0, 'wildfire': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train:\")\n",
        "print(f\"Found {len(train_data)} images belonging to {train_data.classes} classes.\")\n",
        "print(\"Test:\")\n",
        "print(f\"Found {len(test_data)} images belonging to {test_data.classes} classes.\")\n",
        "print(\"Val:\")\n",
        "print(f\"Found {len(val_data)} images belonging to {val_data.classes} classes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zsjNNXerjLE",
        "outputId": "7740a6f6-bcd3-4079-de09-bd8f701c6baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:\n",
            "Found 212 images belonging to ['nowildfire', 'wildfire'] classes.\n",
            "Test:\n",
            "Found 66 images belonging to ['nowildfire', 'wildfire'] classes.\n",
            "Val:\n",
            "Found 65 images belonging to ['nowildfire', 'wildfire'] classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the current directory\n",
        "current_dir = os.getcwd()\n",
        "print(f\"Current directory: {current_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYh9cUvorlEv",
        "outputId": "43fc1573-bbaf-485c-ef73-79751a2d04af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _plot_learning_curves(train_losses, train_accs, val_losses, val_accs):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.plot(train_losses, label='train')\n",
        "    plt.plot(val_losses, label='eval')\n",
        "    plt.legend()\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy [%]')\n",
        "    plt.plot(train_accs, label='train')\n",
        "    plt.plot(val_accs, label='eval')\n",
        "    plt.show()  # Not needed when using 'agg'"
      ],
      "metadata": {
        "id": "-WqDVSA8sLPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_single_epoch(train_loader: torch.utils.data.DataLoader,\n",
        "                       model: torch.nn.Module,\n",
        "                       optimizer: torch.optim,\n",
        "                       criterion: torch.nn.functional,\n",
        "                       epoch: int,\n",
        "                       log_interval: int,\n",
        "                       ) -> Tuple[float, float]:\n",
        "    # Activate the train=True flag inside the model\n",
        "    model.train()\n",
        "\n",
        "    train_loss = []\n",
        "    acc = 0.\n",
        "    avg_weight = 0.1\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        # Move input data and labels to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Set model gradients to 0.\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward batch of images through the model\n",
        "        output = model(data)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Compute backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters of the model\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute metrics\n",
        "        acc += compute_accuracy(output, target)\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "    avg_acc = 100. * acc / len(train_loader.dataset)\n",
        "\n",
        "    return np.mean(train_loss), avg_acc"
      ],
      "metadata": {
        "id": "le4AEIKKscHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()  # decorator: avoid computing gradients\n",
        "def val_single_epoch(\n",
        "        val_loader: torch.utils.data.DataLoader,\n",
        "        model: torch.nn.Module,\n",
        "        criterion: torch.nn.functional\n",
        "        ) -> Tuple[float, float]:\n",
        "\n",
        "    # Dectivate the train=True flag inside the model\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss = []\n",
        "    acc = 0\n",
        "    for data, target in val_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        # Apply the loss criterion and accumulate the loss\n",
        "        eval_loss.append(criterion(output, target).item())\n",
        "\n",
        "        # compute number of correct predictions in the batch\n",
        "        acc += compute_accuracy(output, target)\n",
        "\n",
        "    # Average accuracy across all correct predictions batches now\n",
        "    eval_acc = 100. * acc / len(val_loader.dataset)\n",
        "    eval_loss = np.mean(eval_loss)\n",
        "    print('\\Validation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        eval_loss, acc, len(val_loader.dataset), eval_acc,\n",
        "        ))\n",
        "    return eval_loss, eval_acc"
      ],
      "metadata": {
        "id": "TwA1l3Jksjbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_loader: torch.utils.data.DataLoader,\n",
        "                val_loader: torch.utils.data.DataLoader,\n",
        "                test_loader: torch.utils.data.DataLoader,\n",
        "                hparams: dict\n",
        "                ) -> deeplabv3_resnet50:\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "\n",
        "    # Define pretrained ResNet-50 model using TorchVision DeepLabV3 architecture\n",
        "    model = deeplabv3_resnet50(pretrained=True)\n",
        "\n",
        "    # Since the segmented images have 2 classes (wildfire and nowildfire), we change the final layer to 2 classes\n",
        "    model.classifier[4] = torch.nn.Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Select Stochastic gradient descent (SGD) optimizer with a learning rate of 0.01 (optimum for image segmentation)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=hparams['learning_rate'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(hparams['num_epochs']):\n",
        "        # Compute & save the average training loss for the current epoch\n",
        "        train_loss, train_acc = train_single_epoch(\n",
        "            train_loader=train_loader,\n",
        "            model=model,\n",
        "            optimizer=optimizer,\n",
        "            criterion=criterion,\n",
        "            epoch=epoch,\n",
        "            log_interval=hparams[\"log_interval\"]\n",
        "        )\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        val_loss, val_acc = val_single_epoch(\n",
        "            val_loader=val_loader,\n",
        "            model=model,\n",
        "            criterion=criterion\n",
        "        )\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "    final_test_loss, final_test_acc = test_model(\n",
        "        test_loader=test_loader,\n",
        "        model=model,\n",
        "        criterion=criterion\n",
        "    )\n",
        "\n",
        "    # Plot the plots of the learning curves\n",
        "    _plot_learning_curves(train_losses, train_accs, val_losses, val_accs)\n",
        "\n",
        "    # Print or plot final test results\n",
        "    print('Final Test set: Average loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "        final_test_loss, final_test_acc))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "b_GB1guxr6nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(train_loader=train_loader,\n",
        "                    val_loader=val_loader,\n",
        "                    test_loader=test_loader,\n",
        "                    hparams=hparams).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C29q8OXRsrpQ",
        "outputId": "0c52c333-faf2-4bf6-ae7d-f329a92a1988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, path):\n",
        "    torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "gcacnnFms6Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model checkpoint\n",
        "save_path = \"./model.pt\"\n",
        "print(f\"Saving model to {save_path}...\")\n",
        "save_model(model, save_path)\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "ZZ-YPMtQssMR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}