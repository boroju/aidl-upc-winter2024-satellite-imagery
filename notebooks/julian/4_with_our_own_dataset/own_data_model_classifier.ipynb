{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN1B33PYmrbSM88+oNMJTlZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Training a model with our Own Satellite Image dataset"],"metadata":{"id":"JrnTvBV17CGK"}},{"cell_type":"markdown","source":["## Importing Libraries"],"metadata":{"id":"H8FAqaw87MgN"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SclasuX-cab0","executionInfo":{"status":"ok","timestamp":1706973327279,"user_tz":-60,"elapsed":20062,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"f80aa76e-8686-4c88-f175-9f71564e8097"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: imagehash in /usr/local/lib/python3.10/dist-packages (4.3.1)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.23.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash) (9.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.11.4)\n","cuda\n"]}],"source":["import os\n","import glob\n","import numpy as np\n","from numpy import asarray\n","import matplotlib.pyplot as plt\n","import cv2\n","!pip install imagehash\n","import imagehash\n","\n","import torchvision.models.segmentation\n","import torch\n","import torchdata\n","import torchvision.transforms as tf\n","\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","\n","from pickle import dump\n","\n","# Check if GPU parallel computing is available\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)"]},{"cell_type":"code","source":["%pip install geedim -q\n","%pip install torchgeo -q\n","%pip install rioxarray -q"],"metadata":{"id":"xkOvk3cbc8mW","executionInfo":{"status":"ok","timestamp":1706973357444,"user_tz":-60,"elapsed":30185,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import rioxarray"],"metadata":{"id":"ogWLlqP3dp4I","executionInfo":{"status":"ok","timestamp":1706973359398,"user_tz":-60,"elapsed":1974,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Mounting Google Drive"],"metadata":{"id":"cLt711nO7QQl"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"id":"py9Bbp6Qdqfe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973361441,"user_tz":-60,"elapsed":2047,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"5ab43d7a-0c1a-4e01-fa47-dd8279c16ad2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from pathlib import Path\n","from torchgeo.datasets import RasterDataset, unbind_samples, stack_samples\n","from torchgeo.samplers import RandomBatchGeoSampler, RandomGeoSampler, Units\n","from torch.utils.data import DataLoader"],"metadata":{"id":"-e66FyNFdsL6","executionInfo":{"status":"ok","timestamp":1706973361863,"user_tz":-60,"elapsed":424,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Get the current working directory\n","current_dir = os.getcwd()\n","\n","# Print the current working directory\n","current_dir"],"metadata":{"id":"fNeWM8X4gS_Q","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1706973361864,"user_tz":-60,"elapsed":9,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"2e6739ce-0a2b-44d9-c613-c6e4835b284a"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Accomodate Paths"],"metadata":{"id":"jmv_gc1a7UNe"}},{"cell_type":"code","source":["# Get the path to the directory\n","initial_path = \"/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data\"\n","dataset_path = \"/binary_classification_split/\"\n","\n","# List the contents of the directory\n","contents = os.listdir(initial_path + dataset_path)\n","\n","# Print the contents of the directory\n","for item in contents:\n","  print(item)"],"metadata":{"id":"hEAVh6HIgUnc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973361864,"user_tz":-60,"elapsed":7,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"af9a98ba-2570-49ef-bd75-7fa6718eb43f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["valid_masks\n","test_landcovers\n","test_masks\n","train_masks\n","train_landcovers\n","valid_landcovers\n"]}]},{"cell_type":"markdown","source":["## Check Items"],"metadata":{"id":"lu2gao9b7X6a"}},{"cell_type":"code","source":["test_landcovers_path = initial_path + dataset_path + \"/test_landcovers/\"\n","\n","# Contents of the directory\n","test_landcovers_contents = os.listdir(test_landcovers_path)\n","\n","print(\"Test Landcovers items:\")\n","print(len(test_landcovers_contents))"],"metadata":{"id":"69LPB25ahwRG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973361864,"user_tz":-60,"elapsed":6,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"89a04edf-c0e2-4679-8774-5e7240079be4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Landcovers items:\n","49\n"]}]},{"cell_type":"code","source":["test_masks_path = initial_path + dataset_path + \"/test_masks/\"\n","\n","# Contents of the directory\n","test_masks_contents = os.listdir(test_masks_path)\n","\n","print(\"Test Masks items:\")\n","print(len(test_masks_contents))"],"metadata":{"id":"0-YOyX2tidaH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973361864,"user_tz":-60,"elapsed":6,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"e30a5ec8-d4f6-4477-bb63-221309b3337e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Masks items:\n","49\n"]}]},{"cell_type":"code","source":["train_landcovers_path = initial_path + dataset_path + \"/train_landcovers/\"\n","\n","# Contents of the directory\n","train_landcovers_contents = os.listdir(train_landcovers_path)\n","\n","print(\"Train Landcovers items:\")\n","print(len(train_landcovers_contents))"],"metadata":{"id":"YdYmAe0ljAQ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973361864,"user_tz":-60,"elapsed":5,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"2a4e4a34-458d-44d0-aa3a-d5c03e5b23c1"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Landcovers items:\n","161\n"]}]},{"cell_type":"code","source":["train_masks_path = initial_path + dataset_path + \"/train_masks/\"\n","\n","# Contents of the directory\n","train_masks_contents = os.listdir(train_masks_path)\n","\n","print(\"Train Masks items:\")\n","print(len(train_masks_contents))"],"metadata":{"id":"YFdtB3xPjxHc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973361864,"user_tz":-60,"elapsed":5,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"2efe0467-03fd-4d7c-a883-70bbed272527"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Masks items:\n","161\n"]}]},{"cell_type":"code","source":["valid_landcovers_path = initial_path + dataset_path + \"/valid_landcovers/\"\n","\n","# Contents of the directory\n","valid_landcovers_contents = os.listdir(valid_landcovers_path)\n","\n","print(\"Valid Landcovers items:\")\n","print(len(valid_landcovers_contents))"],"metadata":{"id":"qvHPNZB5j5Ol","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973361864,"user_tz":-60,"elapsed":4,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"402a1660-d998-405d-9a6c-8153b5f12e8f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Valid Landcovers items:\n","21\n"]}]},{"cell_type":"code","source":["valid_masks_path = initial_path + dataset_path + \"/valid_masks/\"\n","\n","# Contents of the directory\n","valid_masks_contents = os.listdir(valid_masks_path)\n","\n","print(\"Valid Masks items:\")\n","print(len(valid_masks_contents))"],"metadata":{"id":"QskxaGEskEBL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973361864,"user_tz":-60,"elapsed":4,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"6377dbbf-8b2a-482f-941e-1dedb83f925e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Valid Masks items:\n","21\n"]}]},{"cell_type":"markdown","source":["## This scale function is not working properly (not sure why)\n","\n","Inspired by:\n","https://www.geocorner.net/post/artificial-intelligence-for-geospatial-analysis-with-pytorch-s-torchgeo-part-1"],"metadata":{"id":"ecljdMmD7avc"}},{"cell_type":"code","source":["# THIS IS NOT WORKING\n","# We are passing a transform function to the images dataset to scale correctly the values to reflectance values (division by 10,000).\n","# It only applies to landcovers (not Masks)\n","# def scale(item: dict):\n","#     item['image'] = item['image'] / 10000\n","#     return item"],"metadata":{"id":"kUEZqJlwsdqO","executionInfo":{"status":"ok","timestamp":1706973361864,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Creating RasterDatasets for Satellite Images\n","\n","Inspired by: https://www.geocorner.net/post/artificial-intelligence-for-geospatial-analysis-with-pytorch-s-torchgeo-part-1"],"metadata":{"id":"2FFxBmQ87pzb"}},{"cell_type":"code","source":["from pathlib import Path\n","root = Path(test_landcovers_path)\n","assert root.exists()\n","print(root.as_posix())\n","test_landcovers = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","\n","root = Path(test_masks_path)\n","assert root.exists()\n","print(root.as_posix())\n","test_mask = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","test_mask.is_image = False\n","\n","from pathlib import Path\n","root = Path(train_landcovers_path)\n","assert root.exists()\n","print(root.as_posix())\n","train_landcovers = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","\n","root = Path(train_masks_path)\n","assert root.exists()\n","print(root.as_posix())\n","train_mask = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","train_mask.is_image = False\n","\n","from pathlib import Path\n","root = Path(valid_landcovers_path)\n","assert root.exists()\n","print(root.as_posix())\n","valid_landcovers = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","\n","root = Path(valid_masks_path)\n","assert root.exists()\n","print(root.as_posix())\n","valid_mask = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","valid_mask.is_image = False"],"metadata":{"id":"Wft1Tn6ihQ2K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973368997,"user_tz":-60,"elapsed":7136,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"517ceed7-96d9-41c4-b671-c94e95e0fa92"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/test_landcovers\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/test_masks\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/train_landcovers\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/train_masks\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/valid_landcovers\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/valid_masks\n"]}]},{"cell_type":"markdown","source":["## Combining Landcovers with Masks by using torchgeo power"],"metadata":{"id":"USUrjEEe7x1M"}},{"cell_type":"code","source":["train_dset = train_landcovers & train_mask\n","valid_dset = valid_landcovers & valid_mask\n","test_dset = test_landcovers & test_mask"],"metadata":{"id":"weOty2cwtxjA","executionInfo":{"status":"ok","timestamp":1706973368997,"user_tz":-60,"elapsed":15,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Defining the Hyper-parameters"],"metadata":{"id":"wY9s0CLhPQxN"}},{"cell_type":"code","source":["# Hyperparameters\n","hparams = {\n","    'batch_size': 8,\n","    'num_epochs': 30,\n","    'test_batch_size': 8,\n","    'learning_rate': 0.01,\n","    'weight_decay': 1e-5,\n","    'log_interval': 100,\n","}"],"metadata":{"id":"J-6ODVtsHnLi","executionInfo":{"status":"ok","timestamp":1706973368997,"user_tz":-60,"elapsed":14,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## Generating samplers"],"metadata":{"id":"QJ34g6808AD6"}},{"cell_type":"markdown","source":["### RandomGeoSampler\n","\n","https://torchgeo.readthedocs.io/en/latest/api/samplers.html#torchgeo.samplers.RandomGeoSampler.__init__\n","\n","Parameters:\n","\n","\n","*   dataset (GeoDataset) – dataset to index from\n","*   size (Union[tuple[float, float], float]) – dimensions of each patch\n","*   length (Optional[int]) – number of random samples to draw per epoch (defaults to approximately the maximal number of non-overlapping chips of size size that could be sampled from the dataset)\n","*   roi (Optional[BoundingBox]) – region of interest to sample from (minx, maxx, miny, maxy, mint, maxt) (defaults to the bounds of dataset.index)\n","*   units (Units) – defines if size is in pixel or CRS units\n"],"metadata":{"id":"b_nqhsBrHFAE"}},{"cell_type":"code","source":["train_sampler = RandomGeoSampler(train_landcovers, size=512, length=160, units=Units.PIXELS)\n","valid_sampler = RandomGeoSampler(valid_landcovers, size=512, length=20, units=Units.PIXELS)\n","test_sampler = RandomGeoSampler(test_landcovers, size=512, length=50, units=Units.PIXELS)"],"metadata":{"id":"0TOKiv6zv6We","executionInfo":{"status":"ok","timestamp":1706973369345,"user_tz":-60,"elapsed":362,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Dataloaders attempt"],"metadata":{"id":"O5Q3MTLX8DED"}},{"cell_type":"code","source":["train_dataloader = DataLoader(train_dset, sampler=train_sampler, batch_size=hparams['batch_size'], collate_fn=stack_samples)\n","valid_dataloader = DataLoader(valid_dset, sampler=valid_sampler, batch_size=hparams['batch_size'], collate_fn=stack_samples)\n","test_dataloader = DataLoader(test_dset, sampler=test_sampler, batch_size=hparams['batch_size'], collate_fn=stack_samples)\n","\n","train_batch = next(iter(train_dataloader))\n","valid_batch = next(iter(valid_dataloader))\n","test_batch = next(iter(test_dataloader))\n","train_batch.keys(), valid_batch.keys()"],"metadata":{"id":"_9OJOOzEwzPL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973373619,"user_tz":-60,"elapsed":4276,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"31595c80-a5d8-45cd-e7ab-47176fa536ac"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(dict_keys(['crs', 'bbox', 'image', 'mask']),\n"," dict_keys(['crs', 'bbox', 'image', 'mask']))"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Batch Visualization\n","\n","The function plot_batch will check automatically the number of items in the batch and if there are masks associated to arrange the output grid accordingly."],"metadata":{"id":"ro_yVsLW0vrD"}},{"cell_type":"code","source":["from typing import Iterable, List\n","\n","\n","def plot_imgs(images: Iterable, axs: Iterable, chnls: List[int] = [2, 1, 0], bright: float = 3.):\n","  for img, ax in zip(images, axs):\n","    image = img\n","    print(image.shape)\n","    # print(image)\n","    # Replace the tensor with your actual geotiff tensor\n","    geotiff_tensor = image.permute(1, 2, 0)\n","\n","    # Check the shape of the tensor\n","    height, width, bands = geotiff_tensor.shape\n","\n","    # Assuming it's an RGB image\n","    if bands == 3:\n","      # Normalize pixel values to the range [0, 1]\n","      normalized_tensor = geotiff_tensor / 255.0\n","\n","      # Reshape the tensor to (height, width, bands) for plotting\n","      reshaped_tensor = normalized_tensor.reshape((height, width, bands))\n","\n","      # Display the image using matplotlib\n","      ax.imshow(reshaped_tensor)\n","      ax.axis('off')  # Turn off axis labels\n","\n","    else:\n","      print(\"The tensor does not represent an RGB image. Visualization not supported.\")\n","\n","\n","def plot_msks(masks: Iterable, axs: Iterable):\n","    for mask, ax in zip(masks, axs):\n","        print(mask.shape)\n","        # ax.imshow(mask.squeeze().numpy(), cmap='Blues')\n","        ax.imshow(mask.squeeze().numpy())\n","        ax.axis('off')\n","\n","\n","def plot_batch(batch: dict, bright: float = 3., cols: int = 4, width: int = 5, chnls: List[int] = [2, 1, 0]):\n","\n","    # Get the samples and the number of items in the batch\n","    samples = unbind_samples(batch.copy())\n","\n","    # if batch contains images and masks, the number of images will be doubled\n","    n = 2 * len(samples) if ('image' in batch) and ('mask' in batch) else len(samples)\n","\n","    # calculate the number of rows in the grid\n","    rows = n//cols + (1 if n%cols != 0 else 0)\n","\n","    # create a grid\n","    _, axs = plt.subplots(rows, cols, figsize=(cols*width, rows*width))\n","\n","    if ('image' in batch) and ('mask' in batch):\n","        # plot the images on the even axis\n","        plot_imgs(images=map(lambda x: x['image'], samples), axs=axs.reshape(-1)[::2], chnls=chnls, bright=bright) #type: ignore\n","\n","        # plot the masks on the odd axis\n","        plot_msks(masks=map(lambda x: x['mask'], samples), axs=axs.reshape(-1)[1::2]) #type: ignore\n","\n","    else:\n","\n","        if 'image' in batch:\n","            plot_imgs(images=map(lambda x: x['image'], samples), axs=axs.reshape(-1), chnls=chnls, bright=bright) #type: ignore\n","\n","        elif 'mask' in batch:\n","            plot_msks(masks=map(lambda x: x['mask'], samples), axs=axs.reshape(-1)) #type: ignore"],"metadata":{"id":"oYoSwh1ByMVI","executionInfo":{"status":"ok","timestamp":1706973373619,"user_tz":-60,"elapsed":15,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["plot_batch(train_batch)"],"metadata":{"id":"tN0_7FJx1Rg7","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1eY4TKi5IHmDnqyIGqVGcLLlTBD_yPBNf"},"executionInfo":{"status":"ok","timestamp":1706973379753,"user_tz":-60,"elapsed":6148,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"916efad1-c8bc-4b32-df2d-ce8b1fc28ce2"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Data Normalization (Standardization)\n","\n","Normally, machine learning methods (deep learning included) benefit from feature scaling. That means standard deviation around 1 and zero mean, by applying the following formula (actually normalization is different from standardization, but I will leave the explanation to the reader: https://www.naukri.com/learning/articles/normalization-and-standardization/)\n","\n","To do that, we need to first find the mean and standard deviation for each one of the 6s channels in the dataset.\n","\n","Let’s define a function calculate these statistics and write its results in the variables mean and std. We will use our previously installed rasterio package to open the images and perform a simple average over the statistics for each batch/channel. For the standard deviation, this method is an approximation. For a more precise calculation, please refer to: http://notmatthancock.github.io/2017/03/23/simple-batch-stat-updates.htm."],"metadata":{"id":"WJLx6PNb5ZG1"}},{"cell_type":"code","source":["import rasterio as rio\n","\n","def calc_statistics(dset: RasterDataset):\n","        \"\"\"\n","        Calculate the statistics (mean and std) for the entire dataset\n","        Warning: This is an approximation. The correct value should take into account the\n","        mean for the whole dataset for computing individual stds.\n","        For correctness I suggest checking: http://notmatthancock.github.io/2017/03/23/simple-batch-stat-updates.html\n","        \"\"\"\n","\n","        # To avoid loading the entire dataset in memory, we will loop through each img\n","        # The filenames will be retrieved from the dataset's rtree index\n","        files = [item.object for item in dset.index.intersection(dset.index.bounds, objects=True)]\n","\n","        # Reseting statistics\n","        accum_mean = 0\n","        accum_std = 0\n","\n","        for file in files:\n","            img = rio.open(file).read()/10000 #type: ignore\n","            accum_mean += img.reshape((img.shape[0], -1)).mean(axis=1)\n","            accum_std += img.reshape((img.shape[0], -1)).std(axis=1)\n","\n","        # at the end, we shall have 2 vectors with lenght n=chnls\n","        # we will average them considering the number of images\n","        return accum_mean / len(files), accum_std / len(files)\n","\n","print(\"Test Landcovers - Image Normalization\")\n","mean, std = calc_statistics(test_landcovers)\n","print(mean, std)\n","print()\n","print(\"Valid Landcovers - Image Normalization\")\n","mean, std = calc_statistics(valid_landcovers)\n","print(mean, std)\n","print()\n","print(\"Train Landcovers - Image Normalization\")\n","mean, std = calc_statistics(train_landcovers)\n","print(mean, std)\n","print()\n","print(\"Mean: \" + str(mean))\n","print(\"Std: \" + str(std))"],"metadata":{"id":"sBrAWuli4uvS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973410609,"user_tz":-60,"elapsed":30869,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"f885ae14-04fb-49ac-9f2e-9587462a7d5c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Landcovers - Image Normalization\n","[0.00657766 0.00804456 0.0075479 ] [0.00338505 0.00294967 0.00194538]\n","\n","Valid Landcovers - Image Normalization\n","[0.00672649 0.00835924 0.00780101] [0.00335708 0.00281504 0.00189687]\n","\n","Train Landcovers - Image Normalization\n","[0.00642393 0.00799009 0.00753127] [0.00329464 0.00282698 0.0018531 ]\n","\n","Mean: [0.00642393 0.00799009 0.00753127]\n","Std: [0.00329464 0.00282698 0.0018531 ]\n"]}]},{"cell_type":"markdown","source":["## MyNormalize\n","\n","https://www.geocorner.net/post/artificial-intelligence-for-geospatial-analysis-with-pytorch-s-torchgeo-part-2\n","\n","Here we have 6 values in each list. Now we have to use these values to normalize the values every time a batch is created by the dataloader and passed to the trainer. Additionally, if we want to visualize this batch we need to “revert” the standardization, otherwise the true color will not be correct. We will then create a class that will do the trick. We are going to inherit it from the torch.nn.Module class, and define the forward method and also the revert method to “undo” the normalization.\n"],"metadata":{"id":"SB3yhWpT62R2"}},{"cell_type":"code","source":["class MyNormalize(torch.nn.Module):\n","    def __init__(self, mean: List[float], stdev: List[float]):\n","        super().__init__()\n","\n","        self.mean = torch.Tensor(mean)[:, None, None]\n","        self.std = torch.Tensor(stdev)[:, None, None]\n","\n","    def forward(self, inputs: dict):\n","\n","        x = inputs[\"image\"][..., : len(self.mean), :, :]\n","\n","        # if batch\n","        if inputs[\"image\"].ndim == 4:\n","            x = (x - self.mean[None, ...]) / self.std[None, ...]\n","\n","        else:\n","            x = (x - self.mean) / self.std\n","\n","        inputs[\"image\"][..., : len(self.mean), :, :] = x\n","\n","        return inputs\n","\n","    def revert(self, inputs: dict):\n","        \"\"\"\n","        De-normalize the batch.\n","        Args:\n","            inputs (dict): Dictionary with the 'image' key\n","        \"\"\"\n","\n","        x = inputs[\"image\"][..., : len(self.mean), :, :]\n","\n","        # if batch\n","        if x.ndim == 4:\n","            x = inputs[\"image\"][:, : len(self.mean), ...]\n","            x = x * self.std[None, ...] + self.mean[None, ...]\n","        else:\n","            x = x * self.std + self.mean\n","\n","        inputs[\"image\"][..., : len(self.mean), :, :] = x\n","\n","        return inputs"],"metadata":{"id":"kQrR-mdR6tLE","executionInfo":{"status":"ok","timestamp":1706973410609,"user_tz":-60,"elapsed":21,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## MyNormalize - instantiated\n","\n","Once the class is defined, we can instantiate it with the mean and std values obtained from our dataset and test the forward pass and the revert pass (code output has been suppressed)."],"metadata":{"id":"4f-N5tEZ8bac"}},{"cell_type":"code","source":["# THIS IS NOT WORKING AS EXPECTED NEITHER\n","# By using train_batch which has larger length\n","normalize = MyNormalize(mean=mean, stdev=std)\n","norm_batch = normalize(train_batch)\n","plot_batch(norm_batch)\n","\n","batch = normalize.revert(norm_batch)\n","plot_batch(batch)"],"metadata":{"id":"crjeDuuL8SCf","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"11FE8lETv1NxMxnZVwehiLd-PsJhoQF2y"},"executionInfo":{"status":"ok","timestamp":1706973416233,"user_tz":-60,"elapsed":5643,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"d04dce0e-797e-4f1a-b5cf-b7a40912564c"},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# Torchgeo Models\n","\n","https://torchgeo.readthedocs.io/en/stable/api/models.html#torchgeo.models.resnet18"],"metadata":{"id":"nLntmEAWUoe1"}},{"cell_type":"code","source":["!pip install torchgeo lightly"],"metadata":{"id":"niqxUqrhciZN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973421668,"user_tz":-60,"elapsed":5438,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"650f553a-6deb-4216-8883-b3c57acc0b13"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchgeo in /usr/local/lib/python3.10/dist-packages (0.5.1)\n","Requirement already satisfied: lightly in /usr/local/lib/python3.10/dist-packages (1.4.26)\n","Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.7.0)\n","Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.9.5)\n","Requirement already satisfied: kornia>=0.6.9 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.7.1)\n","Requirement already satisfied: lightning[pytorch-extra]>=2 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (2.1.4)\n","Requirement already satisfied: matplotlib>=3.3.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (3.7.1)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.23.5)\n","Requirement already satisfied: pandas>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.5.3)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (9.4.0)\n","Requirement already satisfied: pyproj>=3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (3.6.1)\n","Requirement already satisfied: rasterio>=1.2 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.3.9)\n","Requirement already satisfied: rtree>=1 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.2.0)\n","Requirement already satisfied: segmentation-models-pytorch>=0.2 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.3.3)\n","Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (2.0.2)\n","Requirement already satisfied: timm>=0.4.12 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.9.2)\n","Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (2.1.0+cu121)\n","Requirement already satisfied: torchmetrics>=0.10 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.3.0.post0)\n","Requirement already satisfied: torchvision>=0.13 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.16.0+cu121)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly) (2023.11.17)\n","Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.3.2)\n","Requirement already satisfied: lightly-utils~=0.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (0.0.2)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.8.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.31.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.16.0)\n","Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.10/dist-packages (from lightly) (4.66.1)\n","Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.0.7)\n","Requirement already satisfied: pydantic<2,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.10.14)\n","Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.10/dist-packages (from lightly) (3.1.15)\n","Requirement already satisfied: pytorch-lightning>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.1.4)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (23.2.0)\n","Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (8.1.7)\n","Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (1.1.1)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (0.7.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (67.7.2)\n","Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (23.2)\n","Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (6.0.1)\n","Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (2023.6.0)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (0.10.1)\n","Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (4.5.0)\n","Requirement already satisfied: bitsandbytes<1.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (0.42.0)\n","Requirement already satisfied: jsonargparse[signatures]<5.0,>=4.26.1 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (4.27.4)\n","Requirement already satisfied: rich<14.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (13.7.0)\n","Requirement already satisfied: tensorboardX<3.0,>=2.2 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (2.6.2.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (3.1.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.3->torchgeo) (2023.4)\n","Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->torchgeo) (2.4.0)\n","Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->torchgeo) (1.4.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.6)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch>=0.2->torchgeo) (0.7.4)\n","Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch>=0.2->torchgeo) (0.7.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm>=0.4.12->torchgeo) (0.20.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.4.12->torchgeo) (0.4.2)\n","Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch>=0.2->torchgeo) (4.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (2.1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes<1.0->lightning[pytorch-extra]>=2->torchgeo) (1.11.4)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (3.9.3)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]<5.0,>=4.26.1->lightning[pytorch-extra]>=2->torchgeo) (0.15)\n","Requirement already satisfied: typeshed-client>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]<5.0,>=4.26.1->lightning[pytorch-extra]>=2->torchgeo) (2.4.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]>=2->torchgeo) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]>=2->torchgeo) (2.16.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX<3.0,>=2.2->lightning[pytorch-extra]>=2->torchgeo) (3.20.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->torchgeo) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->torchgeo) (1.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (4.0.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]>=2->torchgeo) (0.1.2)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<5.0,>=4.26.1->lightning[pytorch-extra]>=2->torchgeo) (6.1.1)\n"]}]},{"cell_type":"code","source":["!pip install timm==0.9.2"],"metadata":{"id":"9zNPdPPRggoC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706973431028,"user_tz":-60,"elapsed":9366,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"6098f748-3b4c-4c58-c81f-e1cfc50acd6e"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: timm==0.9.2 in /usr/local/lib/python3.10/dist-packages (0.9.2)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2) (2.1.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2) (0.16.0+cu121)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2) (0.20.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.2) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.2) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.2) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.2) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.2) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.2) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2) (4.66.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2) (23.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.9.2) (1.23.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.9.2) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm==0.9.2) (2.1.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.2) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm==0.9.2) (1.3.0)\n"]}]},{"cell_type":"code","source":["import timm\n","from torchgeo.models import ResNet50_Weights\n","\n","weights = ResNet50_Weights.SENTINEL2_ALL_MOCO\n","model = timm.create_model(\"resnet50\", in_chans=weights.meta[\"in_chans\"], num_classes=2)"],"metadata":{"id":"5DvgFIwRQ_f-","executionInfo":{"status":"ok","timestamp":1706974946395,"user_tz":-60,"elapsed":709,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["import tempfile\n","\n","accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n","default_root_dir = os.path.join(tempfile.gettempdir(), \"experiments\")"],"metadata":{"id":"t3ck-yTdcRLo","executionInfo":{"status":"ok","timestamp":1706974946396,"user_tz":-60,"elapsed":5,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":77,"outputs":[]},{"cell_type":"code","source":["from lightning.pytorch import Trainer\n","\n","trainer = Trainer(\n","    accelerator=accelerator,\n","    default_root_dir=default_root_dir,\n","    fast_dev_run=False,\n","    log_every_n_steps=1,\n","    min_epochs=1,\n","    max_epochs=10,\n",")"],"metadata":{"id":"B9UirEQrcSiR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706974946396,"user_tz":-60,"elapsed":5,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"32ea2c2d-b4c6-4381-a1bf-165a75024b43"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO: GPU available: True (cuda), used: True\n","INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO: TPU available: False, using: 0 TPU cores\n","INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO: IPU available: False, using: 0 IPUs\n","INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO: HPU available: False, using: 0 HPUs\n","INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"]}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UNjUnfZkpZD","executionInfo":{"status":"ok","timestamp":1706974946396,"user_tz":-60,"elapsed":4,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"34ae9fbd-5b36-4fb3-d2ce-16841697fe3d"},"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (act1): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (drop_block): Identity()\n","      (act2): ReLU(inplace=True)\n","      (aa): Identity()\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","  )\n","  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n","  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":79}]},{"cell_type":"code","source":["from torchvision.models.segmentation import deeplabv3_resnet50\n","# from torchvision.models.segmentation import DeepLabV3_ResNet50_Weights"],"metadata":{"id":"5TtV-Jfmp2Pa","executionInfo":{"status":"ok","timestamp":1706975331072,"user_tz":-60,"elapsed":267,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":96,"outputs":[]},{"cell_type":"code","source":["model = deeplabv3_resnet50(weights=None, num_classes=2)\n","\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UJGWO9hjoxb0","executionInfo":{"status":"ok","timestamp":1706975333367,"user_tz":-60,"elapsed":764,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"dfe6327a-e468-4e4d-8fc5-1c9eddb138b9"},"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeepLabV3(\n","  (backbone): IntermediateLayerGetter(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","  )\n","  (classifier): DeepLabHead(\n","    (0): ASPP(\n","      (convs): ModuleList(\n","        (0): Sequential(\n","          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","        (1): ASPPConv(\n","          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","        (2): ASPPConv(\n","          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","        (3): ASPPConv(\n","          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU()\n","        )\n","        (4): ASPPPooling(\n","          (0): AdaptiveAvgPool2d(output_size=1)\n","          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): ReLU()\n","        )\n","      )\n","      (project): Sequential(\n","        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU()\n","        (3): Dropout(p=0.5, inplace=False)\n","      )\n","    )\n","    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): ReLU()\n","    (4): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n","  )\n",")"]},"metadata":{},"execution_count":97}]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","backbone = model.get_submodule('backbone')\n","\n","conv = nn.modules.conv.Conv2d(\n","    in_channels=3,\n","    out_channels=64,\n","    kernel_size=(7, 7),\n","    stride=(2, 2),\n","    padding=(3, 3),\n","    bias=False\n",")\n","backbone.register_module('conv1', conv)\n","\n","pred = model(torch.randn(3, 3, 512, 512))\n","pred['out'].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ik2E36ejo6wm","executionInfo":{"status":"ok","timestamp":1706975367576,"user_tz":-60,"elapsed":21268,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"4cc18cf0-88df-4303-a47f-c4067570b8a7"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 2, 512, 512])"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["from typing import Iterable, List, Callable, Optional\n","\n","def train_loop(\n","    epochs: int,\n","    train_dl: DataLoader,\n","    val_dl: Optional[DataLoader],\n","    model: nn.Module,\n","    loss_fn: Callable,\n","    optimizer: torch.optim.Optimizer,\n","    acc_fns: Optional[List]=None,\n","    batch_tfms: Optional[Callable]=None\n","):\n","    # size = len(dataloader.dataset)\n","    cuda_model = model.cuda()\n","\n","    for epoch in range(epochs):\n","        accum_loss = 0\n","        for batch in train_dl:\n","\n","            if batch_tfms is not None:\n","                batch = batch_tfms(batch)\n","\n","            X = batch['image'].cuda()\n","            y = batch['mask'].type(torch.long).cuda()\n","            pred = cuda_model(X)['out']\n","            loss = loss_fn(pred, y)\n","\n","            # BackProp\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # update the accum loss\n","            accum_loss += float(loss) / len(train_dl)\n","\n","        # Testing against the validation dataset\n","        if acc_fns is not None and val_dl is not None:\n","            # reset the accuracies metrics\n","            acc = [0.] * len(acc_fns)\n","\n","            with torch.no_grad():\n","                for batch in val_dl:\n","\n","                    if batch_tfms is not None:\n","                        batch = batch_tfms(batch)\n","\n","                    X = batch['image'].type(torch.float32).cuda()\n","                    y = batch['mask'].type(torch.long).cuda()\n","\n","                    pred = cuda_model(X)['out']\n","\n","                    for i, acc_fn in enumerate(acc_fns):\n","                        acc[i] = float(acc[i] + acc_fn(pred, y)/len(val_dl))\n","\n","            # at the end of the epoch, print the errors, etc.\n","            print(f'Epoch {epoch}: Train Loss={accum_loss:.5f} - Accs={[round(a, 3) for a in acc]}')\n","        else:\n","\n","            print(f'Epoch {epoch}: Train Loss={accum_loss:.5f}')"],"metadata":{"id":"3oW7vpFtqX0v","executionInfo":{"status":"ok","timestamp":1706975403798,"user_tz":-60,"elapsed":248,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import jaccard_score\n","\n","def oa(pred, y):\n","    flat_y = y.squeeze()\n","    flat_pred = pred.argmax(dim=1)\n","    acc = torch.count_nonzero(flat_y == flat_pred) / torch.numel(flat_y)\n","    return acc\n","\n","def iou(pred, y):\n","    flat_y = y.cpu().numpy().squeeze()\n","    flat_pred = pred.argmax(dim=1).detach().cpu().numpy()\n","    return jaccard_score(flat_y.reshape(-1), flat_pred.reshape(-1), zero_division=1.)\n","\n","def loss(p, t):\n","    return torch.nn.functional.cross_entropy(p, t.squeeze())\n"],"metadata":{"id":"l8zMfaLjqbjq","executionInfo":{"status":"ok","timestamp":1706975412009,"user_tz":-60,"elapsed":346,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":100,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(model.parameters(), lr=hparams['learning_rate'], weight_decay=hparams['weight_decay'])\n","train_loop(hparams['num_epochs'], train_dataloader, valid_dataloader, model, loss, optimizer, acc_fns=[oa, iou])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vlyBA-qqfx2","executionInfo":{"status":"ok","timestamp":1706977533140,"user_tz":-60,"elapsed":2042024,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"a8c0aed7-3abc-4787-9067-6b2a6ad55e80"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0: Train Loss=0.85751 - Accs=[0.514, 0.009]\n","Epoch 1: Train Loss=0.68102 - Accs=[0.577, 0.0]\n","Epoch 2: Train Loss=0.67359 - Accs=[0.602, 0.0]\n","Epoch 3: Train Loss=0.72635 - Accs=[0.602, 0.0]\n","Epoch 4: Train Loss=0.69472 - Accs=[0.707, 0.0]\n","Epoch 5: Train Loss=0.67281 - Accs=[0.589, 0.284]\n","Epoch 6: Train Loss=0.66357 - Accs=[0.839, 0.679]\n","Epoch 7: Train Loss=0.65051 - Accs=[0.523, 0.25]\n","Epoch 8: Train Loss=0.64286 - Accs=[0.613, 0.266]\n","Epoch 9: Train Loss=0.65576 - Accs=[0.69, 0.441]\n","Epoch 10: Train Loss=0.68486 - Accs=[0.624, 0.327]\n","Epoch 11: Train Loss=0.60241 - Accs=[0.715, 0.496]\n","Epoch 12: Train Loss=0.67743 - Accs=[0.434, 0.341]\n","Epoch 13: Train Loss=0.71112 - Accs=[0.659, 0.52]\n","Epoch 14: Train Loss=0.66605 - Accs=[0.484, 0.258]\n","Epoch 15: Train Loss=0.68843 - Accs=[0.755, 0.415]\n","Epoch 16: Train Loss=0.67100 - Accs=[0.757, 0.481]\n","Epoch 17: Train Loss=0.59414 - Accs=[0.562, 0.141]\n","Epoch 18: Train Loss=0.67157 - Accs=[0.65, 0.433]\n","Epoch 19: Train Loss=0.62007 - Accs=[0.456, 0.174]\n","Epoch 20: Train Loss=0.69097 - Accs=[0.678, 0.0]\n","Epoch 21: Train Loss=0.64202 - Accs=[0.522, 0.0]\n","Epoch 22: Train Loss=0.65950 - Accs=[0.44, 0.136]\n","Epoch 23: Train Loss=0.62419 - Accs=[0.661, 0.313]\n","Epoch 24: Train Loss=0.61996 - Accs=[0.656, 0.425]\n","Epoch 25: Train Loss=0.63735 - Accs=[0.686, 0.36]\n","Epoch 26: Train Loss=0.67036 - Accs=[0.501, 0.36]\n","Epoch 27: Train Loss=0.65135 - Accs=[0.484, 0.339]\n","Epoch 28: Train Loss=0.62114 - Accs=[0.623, 0.363]\n","Epoch 29: Train Loss=0.57954 - Accs=[0.876, 0.774]\n"]}]}]}