{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"19GKll0QZhM6P2mul9JNVWpp5ad5-O9xG","timestamp":1707050553622},{"file_id":"198DPPsNF4LgE7wlMK_7AY6ESbyNG7d0A","timestamp":1707038903872},{"file_id":"1a5U6k7y92C5m-TnEbW_YomxIZOF0obuU","timestamp":1707037706203},{"file_id":"1LQ1fcQTDZM4LfJSsG1-qzLTrXXTukyP8","timestamp":1707031361772}],"gpuType":"T4","authorship_tag":"ABX9TyMXo7RMkOa1YIdnPY3n4PLK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Training a model with our Own Satellite Image dataset"],"metadata":{"id":"JrnTvBV17CGK"}},{"cell_type":"markdown","source":["## Importing Libraries"],"metadata":{"id":"H8FAqaw87MgN"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SclasuX-cab0","executionInfo":{"status":"ok","timestamp":1707050698083,"user_tz":-60,"elapsed":12188,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"d8c6108d-b4f7-4524-ba84-2638d746b1a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting imagehash\n","  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/296.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/296.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.23.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash) (9.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imagehash) (1.11.4)\n","Installing collected packages: imagehash\n","Successfully installed imagehash-4.3.1\n","cuda\n"]}],"source":["import os\n","import glob\n","import numpy as np\n","from numpy import asarray\n","import matplotlib.pyplot as plt\n","import cv2\n","!pip install imagehash\n","import imagehash\n","\n","import torchvision.models.segmentation\n","import torch\n","import torchdata\n","import torchvision.transforms as tf\n","\n","from sklearn.model_selection import train_test_split\n","from PIL import Image\n","\n","from pickle import dump\n","\n","# Check if GPU parallel computing is available\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)"]},{"cell_type":"code","source":["%pip install geedim -q\n","%pip install torchgeo -q\n","%pip install rioxarray -q"],"metadata":{"id":"xkOvk3cbc8mW","executionInfo":{"status":"ok","timestamp":1707050744546,"user_tz":-60,"elapsed":46466,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"91d1b8da-9400-41db-c124-587e455e02db"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.5/378.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m690.3/690.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m535.2/535.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import rioxarray"],"metadata":{"id":"ogWLlqP3dp4I","executionInfo":{"status":"ok","timestamp":1707050745870,"user_tz":-60,"elapsed":1327,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Mounting Google Drive"],"metadata":{"id":"cLt711nO7QQl"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"id":"py9Bbp6Qdqfe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050810297,"user_tz":-60,"elapsed":64428,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"6bb1dcf6-6e3f-441c-a3ea-deb054c477a6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from pathlib import Path\n","from torchgeo.datasets import RasterDataset, unbind_samples, stack_samples\n","from torchgeo.samplers import RandomBatchGeoSampler, RandomGeoSampler, Units\n","from torch.utils.data import DataLoader"],"metadata":{"id":"-e66FyNFdsL6","executionInfo":{"status":"ok","timestamp":1707050810739,"user_tz":-60,"elapsed":445,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Get the current working directory\n","current_dir = os.getcwd()\n","\n","# Print the current working directory\n","current_dir"],"metadata":{"id":"fNeWM8X4gS_Q","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1707050810739,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"a4df695e-59b7-4265-d02d-97f2a8ec86de"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Accomodate Paths"],"metadata":{"id":"jmv_gc1a7UNe"}},{"cell_type":"code","source":["# Get the path to the directory\n","initial_path = \"/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data\"\n","dataset_path = \"/binary_classification_split/\"\n","\n","# List the contents of the directory\n","contents = os.listdir(initial_path + dataset_path)\n","\n","# Print the contents of the directory\n","for item in contents:\n","  print(item)"],"metadata":{"id":"hEAVh6HIgUnc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050812608,"user_tz":-60,"elapsed":1871,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"f56ee469-aa0d-46a2-e773-36360b1cc0fc"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["valid_masks\n","test_landcovers\n","test_masks\n","train_masks\n","train_landcovers\n","valid_landcovers\n"]}]},{"cell_type":"markdown","source":["## Check Items"],"metadata":{"id":"lu2gao9b7X6a"}},{"cell_type":"code","source":["test_landcovers_path = initial_path + dataset_path + \"/test_landcovers/\"\n","\n","# Contents of the directory\n","test_landcovers_contents = os.listdir(test_landcovers_path)\n","\n","print(\"Test Landcovers items:\")\n","print(len(test_landcovers_contents))"],"metadata":{"id":"69LPB25ahwRG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050813684,"user_tz":-60,"elapsed":1078,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"86d2d370-92b9-44e2-a4fe-96ef92b5bcc8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Landcovers items:\n","49\n"]}]},{"cell_type":"code","source":["test_masks_path = initial_path + dataset_path + \"/test_masks/\"\n","\n","# Contents of the directory\n","test_masks_contents = os.listdir(test_masks_path)\n","\n","print(\"Test Masks items:\")\n","print(len(test_masks_contents))"],"metadata":{"id":"0-YOyX2tidaH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050813685,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"e9a3b701-b748-4e4b-f916-da6bdb43ec4a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Masks items:\n","49\n"]}]},{"cell_type":"code","source":["train_landcovers_path = initial_path + dataset_path + \"/train_landcovers/\"\n","\n","# Contents of the directory\n","train_landcovers_contents = os.listdir(train_landcovers_path)\n","\n","print(\"Train Landcovers items:\")\n","print(len(train_landcovers_contents))"],"metadata":{"id":"YdYmAe0ljAQ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050814240,"user_tz":-60,"elapsed":557,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"4bbd37b8-7b92-49f8-9fcb-59dbe12ddd8f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Landcovers items:\n","161\n"]}]},{"cell_type":"code","source":["train_masks_path = initial_path + dataset_path + \"/train_masks/\"\n","\n","# Contents of the directory\n","train_masks_contents = os.listdir(train_masks_path)\n","\n","print(\"Train Masks items:\")\n","print(len(train_masks_contents))"],"metadata":{"id":"YFdtB3xPjxHc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050814240,"user_tz":-60,"elapsed":5,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"123a6bb3-8e93-4e46-80a7-2ffc6d26ab76"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Masks items:\n","161\n"]}]},{"cell_type":"code","source":["valid_landcovers_path = initial_path + dataset_path + \"/valid_landcovers/\"\n","\n","# Contents of the directory\n","valid_landcovers_contents = os.listdir(valid_landcovers_path)\n","\n","print(\"Valid Landcovers items:\")\n","print(len(valid_landcovers_contents))"],"metadata":{"id":"qvHPNZB5j5Ol","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050814240,"user_tz":-60,"elapsed":4,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"0636d7c9-32d7-4b7d-e7f7-508fc8723a7a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Valid Landcovers items:\n","21\n"]}]},{"cell_type":"code","source":["valid_masks_path = initial_path + dataset_path + \"/valid_masks/\"\n","\n","# Contents of the directory\n","valid_masks_contents = os.listdir(valid_masks_path)\n","\n","print(\"Valid Masks items:\")\n","print(len(valid_masks_contents))"],"metadata":{"id":"QskxaGEskEBL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050814240,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"45f1bdcc-29be-4c95-a61f-29045432a89c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Valid Masks items:\n","21\n"]}]},{"cell_type":"markdown","source":["## This scale function is not working properly (not sure why)\n","\n","Inspired by:\n","https://www.geocorner.net/post/artificial-intelligence-for-geospatial-analysis-with-pytorch-s-torchgeo-part-1"],"metadata":{"id":"ecljdMmD7avc"}},{"cell_type":"code","source":["# THIS IS NOT WORKING\n","# We are passing a transform function to the images dataset to scale correctly the values to reflectance values (division by 10,000).\n","# It only applies to landcovers (not Masks)\n","# def scale(item: dict):\n","#     item['image'] = item['image'] / 10000\n","#     return item"],"metadata":{"id":"kUEZqJlwsdqO","executionInfo":{"status":"ok","timestamp":1707050814240,"user_tz":-60,"elapsed":2,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Creating RasterDatasets for Satellite Images\n","\n","Inspired by: https://www.geocorner.net/post/artificial-intelligence-for-geospatial-analysis-with-pytorch-s-torchgeo-part-1"],"metadata":{"id":"2FFxBmQ87pzb"}},{"cell_type":"code","source":["from pathlib import Path\n","root = Path(test_landcovers_path)\n","assert root.exists()\n","print(root.as_posix())\n","test_landcovers = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","\n","root = Path(test_masks_path)\n","assert root.exists()\n","print(root.as_posix())\n","test_mask = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","test_mask.is_image = False\n","\n","from pathlib import Path\n","root = Path(train_landcovers_path)\n","assert root.exists()\n","print(root.as_posix())\n","train_landcovers = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","\n","root = Path(train_masks_path)\n","assert root.exists()\n","print(root.as_posix())\n","train_mask = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","train_mask.is_image = False\n","\n","from pathlib import Path\n","root = Path(valid_landcovers_path)\n","assert root.exists()\n","print(root.as_posix())\n","valid_landcovers = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","\n","root = Path(valid_masks_path)\n","assert root.exists()\n","print(root.as_posix())\n","valid_mask = RasterDataset(paths=root.as_posix(),\n","                                crs='epsg:3395',\n","                                res=10,\n","                                transforms=None)\n","valid_mask.is_image = False"],"metadata":{"id":"Wft1Tn6ihQ2K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050929693,"user_tz":-60,"elapsed":115455,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"55ff61cc-054a-4c9e-da7e-f1ce7d3eb1d9"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/test_landcovers\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/test_masks\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/train_landcovers\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/train_masks\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/valid_landcovers\n","/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/binary_classification_split/valid_masks\n"]}]},{"cell_type":"markdown","source":["## Combining Landcovers with Masks by using torchgeo power"],"metadata":{"id":"USUrjEEe7x1M"}},{"cell_type":"code","source":["train_dset = train_landcovers & train_mask\n","valid_dset = valid_landcovers & valid_mask\n","test_dset = test_landcovers & test_mask"],"metadata":{"id":"weOty2cwtxjA","executionInfo":{"status":"ok","timestamp":1707050929693,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Defining the Hyper-parameters"],"metadata":{"id":"wY9s0CLhPQxN"}},{"cell_type":"code","source":["# Hyperparameters\n","hparams = {\n","    'batch_size': 8,\n","    'num_epochs': 60,\n","    'num_classes': 2,\n","    'test_batch_size': 8,\n","    'learning_rate': 1e-6,\n","    'weight_decay': 1e-3,\n","    'log_interval': 100,\n","}"],"metadata":{"id":"J-6ODVtsHnLi","executionInfo":{"status":"ok","timestamp":1707051758031,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["## Generating samplers"],"metadata":{"id":"QJ34g6808AD6"}},{"cell_type":"markdown","source":["### RandomGeoSampler\n","\n","https://torchgeo.readthedocs.io/en/latest/api/samplers.html#torchgeo.samplers.RandomGeoSampler.__init__\n","\n","Parameters:\n","\n","\n","*   dataset (GeoDataset) – dataset to index from\n","*   size (Union[tuple[float, float], float]) – dimensions of each patch\n","*   length (Optional[int]) – number of random samples to draw per epoch (defaults to approximately the maximal number of non-overlapping chips of size size that could be sampled from the dataset)\n","*   roi (Optional[BoundingBox]) – region of interest to sample from (minx, maxx, miny, maxy, mint, maxt) (defaults to the bounds of dataset.index)\n","*   units (Units) – defines if size is in pixel or CRS units\n"],"metadata":{"id":"b_nqhsBrHFAE"}},{"cell_type":"code","source":["train_sampler = RandomGeoSampler(train_landcovers, size=512, length=160, units=Units.PIXELS)\n","valid_sampler = RandomGeoSampler(valid_landcovers, size=512, length=20, units=Units.PIXELS)\n","test_sampler = RandomGeoSampler(test_landcovers, size=512, length=50, units=Units.PIXELS)"],"metadata":{"id":"0TOKiv6zv6We","executionInfo":{"status":"ok","timestamp":1707050929693,"user_tz":-60,"elapsed":2,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Dataloaders attempt"],"metadata":{"id":"O5Q3MTLX8DED"}},{"cell_type":"code","source":["train_dataloader = DataLoader(train_dset, sampler=train_sampler, batch_size=hparams['batch_size'], collate_fn=stack_samples)\n","valid_dataloader = DataLoader(valid_dset, sampler=valid_sampler, batch_size=hparams['batch_size'], collate_fn=stack_samples)\n","test_dataloader = DataLoader(test_dset, sampler=test_sampler, batch_size=hparams['batch_size'], collate_fn=stack_samples)\n","\n","train_batch = next(iter(train_dataloader))\n","valid_batch = next(iter(valid_dataloader))\n","test_batch = next(iter(test_dataloader))\n","train_batch.keys(), valid_batch.keys()"],"metadata":{"id":"_9OJOOzEwzPL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050940345,"user_tz":-60,"elapsed":10654,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"55e798b3-cb7e-4ac0-a11e-c87f48d6f451"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(dict_keys(['crs', 'bbox', 'image', 'mask']),\n"," dict_keys(['crs', 'bbox', 'image', 'mask']))"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Batch Visualization\n","\n","The function plot_batch will check automatically the number of items in the batch and if there are masks associated to arrange the output grid accordingly."],"metadata":{"id":"ro_yVsLW0vrD"}},{"cell_type":"code","source":["from typing import Iterable, List\n","\n","\n","def plot_imgs(images: Iterable, axs: Iterable, chnls: List[int] = [2, 1, 0], bright: float = 3.):\n","  for img, ax in zip(images, axs):\n","    image = img\n","    print(image.shape)\n","    # print(image)\n","    # Replace the tensor with your actual geotiff tensor\n","    geotiff_tensor = image.permute(1, 2, 0)\n","\n","    # Check the shape of the tensor\n","    height, width, bands = geotiff_tensor.shape\n","\n","    # Assuming it's an RGB image\n","    if bands == 3:\n","      # Normalize pixel values to the range [0, 1]\n","      normalized_tensor = geotiff_tensor / 255.0\n","\n","      # Reshape the tensor to (height, width, bands) for plotting\n","      reshaped_tensor = normalized_tensor.reshape((height, width, bands))\n","\n","      # Display the image using matplotlib\n","      ax.imshow(reshaped_tensor)\n","      ax.axis('off')  # Turn off axis labels\n","\n","    else:\n","      print(\"The tensor does not represent an RGB image. Visualization not supported.\")\n","\n","\n","def plot_msks(masks: Iterable, axs: Iterable):\n","    for mask, ax in zip(masks, axs):\n","        print(mask.shape)\n","        # ax.imshow(mask.squeeze().numpy(), cmap='Blues')\n","        ax.imshow(mask.squeeze().numpy())\n","        ax.axis('off')\n","\n","\n","def plot_batch(batch: dict, bright: float = 3., cols: int = 4, width: int = 5, chnls: List[int] = [2, 1, 0]):\n","\n","    # Get the samples and the number of items in the batch\n","    samples = unbind_samples(batch.copy())\n","\n","    # if batch contains images and masks, the number of images will be doubled\n","    n = 2 * len(samples) if ('image' in batch) and ('mask' in batch) else len(samples)\n","\n","    # calculate the number of rows in the grid\n","    rows = n//cols + (1 if n%cols != 0 else 0)\n","\n","    # create a grid\n","    _, axs = plt.subplots(rows, cols, figsize=(cols*width, rows*width))\n","\n","    if ('image' in batch) and ('mask' in batch):\n","        # plot the images on the even axis\n","        plot_imgs(images=map(lambda x: x['image'], samples), axs=axs.reshape(-1)[::2], chnls=chnls, bright=bright) #type: ignore\n","\n","        # plot the masks on the odd axis\n","        plot_msks(masks=map(lambda x: x['mask'], samples), axs=axs.reshape(-1)[1::2]) #type: ignore\n","\n","    else:\n","\n","        if 'image' in batch:\n","            plot_imgs(images=map(lambda x: x['image'], samples), axs=axs.reshape(-1), chnls=chnls, bright=bright) #type: ignore\n","\n","        elif 'mask' in batch:\n","            plot_msks(masks=map(lambda x: x['mask'], samples), axs=axs.reshape(-1)) #type: ignore"],"metadata":{"id":"oYoSwh1ByMVI","executionInfo":{"status":"ok","timestamp":1707050940346,"user_tz":-60,"elapsed":18,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["plot_batch(train_batch)"],"metadata":{"id":"tN0_7FJx1Rg7","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ggiWuHmUG9-Ae6WCt0_lBZV9wnOJDKM9"},"executionInfo":{"status":"ok","timestamp":1707050950561,"user_tz":-60,"elapsed":10231,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"7f710e6b-d4e9-4e3d-f278-bd19a6589a1d"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Data Normalization (Standardization)\n","\n","Normally, machine learning methods (deep learning included) benefit from feature scaling. That means standard deviation around 1 and zero mean, by applying the following formula (actually normalization is different from standardization, but I will leave the explanation to the reader: https://www.naukri.com/learning/articles/normalization-and-standardization/)\n","\n","To do that, we need to first find the mean and standard deviation for each one of the 6s channels in the dataset.\n","\n","Let’s define a function calculate these statistics and write its results in the variables mean and std. We will use our previously installed rasterio package to open the images and perform a simple average over the statistics for each batch/channel. For the standard deviation, this method is an approximation. For a more precise calculation, please refer to: http://notmatthancock.github.io/2017/03/23/simple-batch-stat-updates.htm."],"metadata":{"id":"WJLx6PNb5ZG1"}},{"cell_type":"markdown","source":["## MyNormalize\n","\n","https://www.geocorner.net/post/artificial-intelligence-for-geospatial-analysis-with-pytorch-s-torchgeo-part-2\n","\n","Here we have 6 values in each list. Now we have to use these values to normalize the values every time a batch is created by the dataloader and passed to the trainer. Additionally, if we want to visualize this batch we need to “revert” the standardization, otherwise the true color will not be correct. We will then create a class that will do the trick. We are going to inherit it from the torch.nn.Module class, and define the forward method and also the revert method to “undo” the normalization.\n"],"metadata":{"id":"SB3yhWpT62R2"}},{"cell_type":"code","source":["class MyNormalize(torch.nn.Module):\n","    def __init__(self, mean: List[float], stdev: List[float]):\n","        super().__init__()\n","\n","        self.mean = torch.Tensor(mean)[:, None, None]\n","        self.std = torch.Tensor(stdev)[:, None, None]\n","\n","    def forward(self, inputs: dict):\n","\n","        x = inputs[\"image\"][..., : len(self.mean), :, :]\n","\n","        # if batch\n","        if inputs[\"image\"].ndim == 4:\n","            x = (x - self.mean[None, ...]) / self.std[None, ...]\n","\n","        else:\n","            x = (x - self.mean) / self.std\n","\n","        inputs[\"image\"][..., : len(self.mean), :, :] = x\n","\n","        return inputs\n","\n","    def revert(self, inputs: dict):\n","        \"\"\"\n","        De-normalize the batch.\n","        Args:\n","            inputs (dict): Dictionary with the 'image' key\n","        \"\"\"\n","\n","        x = inputs[\"image\"][..., : len(self.mean), :, :]\n","\n","        # if batch\n","        if x.ndim == 4:\n","            x = inputs[\"image\"][:, : len(self.mean), ...]\n","            x = x * self.std[None, ...] + self.mean[None, ...]\n","        else:\n","            x = x * self.std + self.mean\n","\n","        inputs[\"image\"][..., : len(self.mean), :, :] = x\n","\n","        return inputs"],"metadata":{"id":"kQrR-mdR6tLE","executionInfo":{"status":"ok","timestamp":1707050950561,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## MyNormalize - instantiated\n","\n","Once the class is defined, we can instantiate it with the mean and std values obtained from our dataset and test the forward pass and the revert pass (code output has been suppressed)."],"metadata":{"id":"4f-N5tEZ8bac"}},{"cell_type":"code","source":["# THIS IS NOT WORKING AS EXPECTED NEITHER\n","# By using train_batch which has larger length\n","# normalize = MyNormalize(mean=mean, stdev=std)\n","# norm_batch = normalize(train_batch)\n","# plot_batch(norm_batch)\n","\n","# batch = normalize.revert(norm_batch)\n","# plot_batch(batch)"],"metadata":{"id":"crjeDuuL8SCf","executionInfo":{"status":"ok","timestamp":1707050950561,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["# Torchgeo Models\n","\n","https://torchgeo.readthedocs.io/en/stable/api/models.html#torchgeo.models.resnet18"],"metadata":{"id":"nLntmEAWUoe1"}},{"cell_type":"code","source":["!pip cache purge"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGGiKUYcI1xH","executionInfo":{"status":"ok","timestamp":1707050950966,"user_tz":-60,"elapsed":408,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"fbbfc9a2-636b-4509-9d57-0c51044c4521"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Files removed: 64\n"]}]},{"cell_type":"code","source":["!pip install torchgeo lightly"],"metadata":{"id":"niqxUqrhciZN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707050950966,"user_tz":-60,"elapsed":4,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"7b6b9375-bfe1-41fd-d9c2-c43fc2837a81"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchgeo in /usr/local/lib/python3.10/dist-packages (0.5.1)\n","Requirement already satisfied: lightly in /usr/local/lib/python3.10/dist-packages (1.4.26)\n","Requirement already satisfied: einops>=0.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.7.0)\n","Requirement already satisfied: fiona>=1.8.19 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.9.5)\n","Requirement already satisfied: kornia>=0.6.9 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.7.1)\n","Requirement already satisfied: lightning[pytorch-extra]>=2 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (2.1.4)\n","Requirement already satisfied: matplotlib>=3.3.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (3.7.1)\n","Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.23.5)\n","Requirement already satisfied: pandas>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.5.3)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (9.4.0)\n","Requirement already satisfied: pyproj>=3 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (3.6.1)\n","Requirement already satisfied: rasterio>=1.2 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.3.9)\n","Requirement already satisfied: rtree>=1 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.2.0)\n","Requirement already satisfied: segmentation-models-pytorch>=0.2 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.3.3)\n","Requirement already satisfied: shapely>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (2.0.2)\n","Requirement already satisfied: timm>=0.4.12 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.9.2)\n","Requirement already satisfied: torch>=1.12 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (2.1.0+cu121)\n","Requirement already satisfied: torchmetrics>=0.10 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (1.3.0.post0)\n","Requirement already satisfied: torchvision>=0.13 in /usr/local/lib/python3.10/dist-packages (from torchgeo) (0.16.0+cu121)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly) (2023.11.17)\n","Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.3.2)\n","Requirement already satisfied: lightly-utils~=0.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (0.0.2)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.8.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.31.0)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.16.0)\n","Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.10/dist-packages (from lightly) (4.66.1)\n","Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.0.7)\n","Requirement already satisfied: pydantic<2,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.10.14)\n","Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.10/dist-packages (from lightly) (3.1.15)\n","Requirement already satisfied: pytorch-lightning>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.1.4)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (23.2.0)\n","Requirement already satisfied: click~=8.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (8.1.7)\n","Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (1.1.1)\n","Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (0.7.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiona>=1.8.19->torchgeo) (67.7.2)\n","Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (23.2)\n","Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (6.0.1)\n","Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (2023.6.0)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (0.10.1)\n","Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (4.5.0)\n","Requirement already satisfied: bitsandbytes<1.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (0.42.0)\n","Requirement already satisfied: jsonargparse[signatures]<5.0,>=4.26.1 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (4.27.4)\n","Requirement already satisfied: rich<14.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (13.7.0)\n","Requirement already satisfied: tensorboardX<3.0,>=2.2 in /usr/local/lib/python3.10/dist-packages (from lightning[pytorch-extra]>=2->torchgeo) (2.6.2.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.3->torchgeo) (3.1.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.3->torchgeo) (2023.4)\n","Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->torchgeo) (2.4.0)\n","Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio>=1.2->torchgeo) (1.4.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.6)\n","Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch>=0.2->torchgeo) (0.7.4)\n","Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch>=0.2->torchgeo) (0.7.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm>=0.4.12->torchgeo) (0.20.3)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.4.12->torchgeo) (0.4.2)\n","Requirement already satisfied: munch in /usr/local/lib/python3.10/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch>=0.2->torchgeo) (4.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12->torchgeo) (2.1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes<1.0->lightning[pytorch-extra]>=2->torchgeo) (1.11.4)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (3.9.3)\n","Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]<5.0,>=4.26.1->lightning[pytorch-extra]>=2->torchgeo) (0.15)\n","Requirement already satisfied: typeshed-client>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from jsonargparse[signatures]<5.0,>=4.26.1->lightning[pytorch-extra]>=2->torchgeo) (2.4.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]>=2->torchgeo) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]>=2->torchgeo) (2.16.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX<3.0,>=2.2->lightning[pytorch-extra]>=2->torchgeo) (3.20.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.12->torchgeo) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12->torchgeo) (1.3.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning[pytorch-extra]>=2->torchgeo) (4.0.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]>=2->torchgeo) (0.1.2)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<5.0,>=4.26.1->lightning[pytorch-extra]>=2->torchgeo) (6.1.1)\n"]}]},{"cell_type":"code","source":["import tempfile\n","\n","accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n","default_root_dir = os.path.join(tempfile.gettempdir(), \"experiments\")"],"metadata":{"id":"t3ck-yTdcRLo","executionInfo":{"status":"ok","timestamp":1707050950966,"user_tz":-60,"elapsed":2,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn"],"metadata":{"id":"5bMPFLXEamZr","executionInfo":{"status":"ok","timestamp":1707050950966,"user_tz":-60,"elapsed":1,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["from typing import Iterable, List, Callable, Optional\n","\n","\n","def train_loop(\n","    epochs: int,\n","    train_dl: DataLoader,\n","    val_dl: Optional[DataLoader],\n","    model: nn.Module,\n","    loss_fn: Callable,\n","    optimizer: torch.optim.Optimizer,\n","    acc_fns: Optional[List]=None,\n","    batch_tfms: Optional[Callable]=None\n",") -> torch.nn.Module:\n","    # size = len(dataloader.dataset)\n","    cuda_model = model.cuda()\n","\n","    for epoch in range(epochs):\n","        accum_loss = 0\n","        for batch in train_dl:\n","\n","            if batch_tfms is not None:\n","                batch = batch_tfms(batch)\n","\n","            X = batch['image'].cuda()\n","            y = batch['mask'].type(torch.long).cuda()\n","            pred = cuda_model(X)\n","            loss = loss_fn(pred, y)\n","\n","            # BackProp\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # update the accum loss\n","            accum_loss += float(loss) / len(train_dl)\n","\n","        # Testing against the validation dataset\n","        if acc_fns is not None and val_dl is not None:\n","            # reset the accuracies metrics\n","            acc = [0.] * len(acc_fns)\n","\n","            with torch.no_grad():\n","                for batch in val_dl:\n","\n","                    if batch_tfms is not None:\n","                        batch = batch_tfms(batch)\n","\n","                    X = batch['image'].type(torch.float32).cuda()\n","                    y = batch['mask'].type(torch.long).cuda()\n","\n","                    pred = cuda_model(X)\n","\n","                    for i, acc_fn in enumerate(acc_fns):\n","                        acc[i] = float(acc[i] + acc_fn(pred, y)/len(val_dl))\n","\n","            # at the end of the epoch, print the errors, etc.\n","            print(f'Epoch {epoch}: Train Loss={accum_loss:.5f} - Accs={[round(a, 3) for a in acc]}')\n","        else:\n","\n","            print(f'Epoch {epoch}: Train Loss={accum_loss:.5f}')\n","\n","    return cuda_model"],"metadata":{"id":"3oW7vpFtqX0v","executionInfo":{"status":"ok","timestamp":1707050950966,"user_tz":-60,"elapsed":1,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import jaccard_score\n","\n","def oa(pred, y):\n","    flat_y = y.squeeze()\n","    flat_pred = pred.argmax(dim=1)\n","    acc = torch.count_nonzero(flat_y == flat_pred) / torch.numel(flat_y)\n","    return acc\n","\n","def iou(pred, y):\n","    flat_y = y.cpu().numpy().squeeze()\n","    flat_pred = pred.argmax(dim=1).detach().cpu().numpy()\n","    return jaccard_score(flat_y.reshape(-1), flat_pred.reshape(-1), zero_division=1.)\n","\n","def loss(p, t):\n","    return torch.nn.functional.cross_entropy(p, t.squeeze())\n"],"metadata":{"id":"l8zMfaLjqbjq","executionInfo":{"status":"ok","timestamp":1707050950966,"user_tz":-60,"elapsed":1,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["## Exploring how FarSeg perfoms\n","\n","Model documentation: https://torchgeo.readthedocs.io/en/v0.4.0/api/models.html#farseg\n","\n","Structure:\n","https://torchgeo.readthedocs.io/en/latest/_modules/torchgeo/models/farseg.html#FarSeg.__init__\n"],"metadata":{"id":"Ylwt0gdeU1rS"}},{"cell_type":"code","source":["from torchgeo.models import FarSeg\n","\n","# Not sure how to pass below weights to FarSeg model\n","# from torchgeo.models import ResNet50_Weights\n","# weights_sent2 = ResNet50_Weights.SENTINEL2_ALL_MOCO"],"metadata":{"id":"W-fWVmejEBKK","executionInfo":{"status":"ok","timestamp":1707051775682,"user_tz":-60,"elapsed":655,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["farseg_model_v5 = FarSeg(backbone=\"resnet50\", classes=hparams['num_classes'], backbone_pretrained=False)"],"metadata":{"id":"vgL-z118LVkj","executionInfo":{"status":"ok","timestamp":1707051776098,"user_tz":-60,"elapsed":3,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","\n","backbone = farseg_model_v5.get_submodule('backbone')\n","\n","conv = nn.modules.conv.Conv2d(\n","    in_channels=3,\n","    out_channels=64,\n","    kernel_size=(7, 7),\n","    stride=(2, 2),\n","    padding=(3, 3),\n","    bias=False\n",")\n","backbone.register_module('conv1', conv)\n","\n","pred = farseg_model_v5(torch.randn(3, 3, 512, 512))\n","pred.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hAtFnxIKOhtd","executionInfo":{"status":"ok","timestamp":1707051783071,"user_tz":-60,"elapsed":6975,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"07bb9de3-5163-48ec-f9de-f9cf86862526"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 2, 512, 512])"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["# Model path\n","model_path = \"/content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/model/\""],"metadata":{"id":"TFl_OJVTEZ_U","executionInfo":{"status":"ok","timestamp":1707051783071,"user_tz":-60,"elapsed":14,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# List the contents of the directory\n","model_contents = os.listdir(model_path)\n","\n","# Print the contents of the directory\n","for item in model_contents:\n","  print(item)"],"metadata":{"id":"eJ2nR_mBEo-s","executionInfo":{"status":"ok","timestamp":1707051783071,"user_tz":-60,"elapsed":13,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"570a7ce9-aadc-44f5-c65d-61beeb3e41ed"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["my_farseg_model_v1.pt\n","my_farseg_model_v2.pt\n","my_farseg_model_v3.pt\n","my_farseg_model_v4.pt\n"]}]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(farseg_model_v5.parameters(), lr=hparams['learning_rate'], weight_decay=hparams['weight_decay'])\n","my_farseg_model_v5 = train_loop(hparams['num_epochs'], train_dataloader, valid_dataloader, farseg_model_v5, loss, optimizer, acc_fns=[oa, iou])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yTPdSLFyTBUt","executionInfo":{"status":"ok","timestamp":1707053712400,"user_tz":-60,"elapsed":1929342,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"d7291e8a-cac7-4852-d774-5738c087bf17"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0: Train Loss=0.70500 - Accs=[0.612, 0.538]\n","Epoch 1: Train Loss=0.70063 - Accs=[0.501, 0.371]\n","Epoch 2: Train Loss=0.70150 - Accs=[0.525, 0.362]\n","Epoch 3: Train Loss=0.69755 - Accs=[0.549, 0.318]\n","Epoch 4: Train Loss=0.69620 - Accs=[0.558, 0.363]\n","Epoch 5: Train Loss=0.69204 - Accs=[0.526, 0.334]\n","Epoch 6: Train Loss=0.68748 - Accs=[0.495, 0.248]\n","Epoch 7: Train Loss=0.69726 - Accs=[0.583, 0.389]\n","Epoch 8: Train Loss=0.69026 - Accs=[0.583, 0.43]\n","Epoch 9: Train Loss=0.68249 - Accs=[0.629, 0.377]\n","Epoch 10: Train Loss=0.68542 - Accs=[0.529, 0.281]\n","Epoch 11: Train Loss=0.68502 - Accs=[0.607, 0.236]\n","Epoch 12: Train Loss=0.67769 - Accs=[0.639, 0.324]\n","Epoch 13: Train Loss=0.67804 - Accs=[0.575, 0.307]\n","Epoch 14: Train Loss=0.66986 - Accs=[0.656, 0.453]\n","Epoch 15: Train Loss=0.66949 - Accs=[0.619, 0.286]\n","Epoch 16: Train Loss=0.67483 - Accs=[0.652, 0.28]\n","Epoch 17: Train Loss=0.67020 - Accs=[0.645, 0.437]\n","Epoch 18: Train Loss=0.67181 - Accs=[0.617, 0.178]\n","Epoch 19: Train Loss=0.67480 - Accs=[0.615, 0.327]\n","Epoch 20: Train Loss=0.66176 - Accs=[0.632, 0.315]\n","Epoch 21: Train Loss=0.67187 - Accs=[0.664, 0.384]\n","Epoch 22: Train Loss=0.66299 - Accs=[0.664, 0.407]\n","Epoch 23: Train Loss=0.65556 - Accs=[0.564, 0.341]\n","Epoch 24: Train Loss=0.67006 - Accs=[0.632, 0.183]\n","Epoch 25: Train Loss=0.66659 - Accs=[0.672, 0.433]\n","Epoch 26: Train Loss=0.67595 - Accs=[0.687, 0.344]\n","Epoch 27: Train Loss=0.63742 - Accs=[0.599, 0.326]\n","Epoch 28: Train Loss=0.67536 - Accs=[0.56, 0.253]\n","Epoch 29: Train Loss=0.67770 - Accs=[0.715, 0.389]\n","Epoch 30: Train Loss=0.64581 - Accs=[0.671, 0.345]\n","Epoch 31: Train Loss=0.66296 - Accs=[0.617, 0.408]\n","Epoch 32: Train Loss=0.63007 - Accs=[0.611, 0.368]\n","Epoch 33: Train Loss=0.66744 - Accs=[0.725, 0.306]\n","Epoch 34: Train Loss=0.64084 - Accs=[0.548, 0.248]\n","Epoch 35: Train Loss=0.66785 - Accs=[0.603, 0.396]\n","Epoch 36: Train Loss=0.65898 - Accs=[0.66, 0.261]\n","Epoch 37: Train Loss=0.65714 - Accs=[0.708, 0.493]\n","Epoch 38: Train Loss=0.63914 - Accs=[0.662, 0.065]\n","Epoch 39: Train Loss=0.65184 - Accs=[0.619, 0.353]\n","Epoch 40: Train Loss=0.65956 - Accs=[0.675, 0.35]\n","Epoch 41: Train Loss=0.65813 - Accs=[0.777, 0.471]\n","Epoch 42: Train Loss=0.63599 - Accs=[0.676, 0.349]\n","Epoch 43: Train Loss=0.65304 - Accs=[0.709, 0.384]\n","Epoch 44: Train Loss=0.65282 - Accs=[0.628, 0.278]\n","Epoch 45: Train Loss=0.65288 - Accs=[0.49, 0.186]\n","Epoch 46: Train Loss=0.62709 - Accs=[0.717, 0.366]\n","Epoch 47: Train Loss=0.64111 - Accs=[0.783, 0.413]\n","Epoch 48: Train Loss=0.69163 - Accs=[0.687, 0.343]\n","Epoch 49: Train Loss=0.62542 - Accs=[0.722, 0.473]\n","Epoch 50: Train Loss=0.65673 - Accs=[0.599, 0.335]\n","Epoch 51: Train Loss=0.66258 - Accs=[0.668, 0.278]\n","Epoch 52: Train Loss=0.64792 - Accs=[0.707, 0.211]\n","Epoch 53: Train Loss=0.66296 - Accs=[0.572, 0.247]\n","Epoch 54: Train Loss=0.59737 - Accs=[0.49, 0.344]\n","Epoch 55: Train Loss=0.64298 - Accs=[0.635, 0.213]\n","Epoch 56: Train Loss=0.64188 - Accs=[0.662, 0.34]\n","Epoch 57: Train Loss=0.63979 - Accs=[0.724, 0.455]\n","Epoch 58: Train Loss=0.63371 - Accs=[0.794, 0.566]\n","Epoch 59: Train Loss=0.62990 - Accs=[0.732, 0.378]\n"]}]},{"cell_type":"code","source":["def save_model(model, path):\n","    torch.save(model.state_dict(), path)"],"metadata":{"id":"4rvxavWFRI_O","executionInfo":{"status":"ok","timestamp":1707053712401,"user_tz":-60,"elapsed":25,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["# Save the model checkpoint\n","save_path = model_path + \"/my_farseg_model_v5.pt\"\n","print(f\"Saving model to {save_path}...\")\n","save_model(my_farseg_model_v5, save_path)\n","print(\"Model saved successfully!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t50LXkE7RZAX","executionInfo":{"status":"ok","timestamp":1707053712993,"user_tz":-60,"elapsed":598,"user":{"displayName":"Julián Esteban Boronat","userId":"11280705151775376844"}},"outputId":"db682025-3400-4ed2-84dd-0399955e6e1d"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving model to /content/drive/MyDrive/_UPC/Postgraduate in Artificial Intelligence with Deep Learning/X-Final Project/Satellite Images/With our own Data/model//my_farseg_model_v5.pt...\n","Model saved successfully!\n"]}]}]}